---
phase: 01-foundation
plan: 03
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/core/redis.py
  - src/core/logging.py
  - src/core/sentry.py
autonomous: true

must_haves:
  truths:
    - "Redis pool can connect and ping"
    - "Structlog outputs JSON with task_id, client_id, agent, timestamp, level, message"
    - "Sentry initializes when DSN provided, skips gracefully when not"
  artifacts:
    - path: "src/core/redis.py"
      provides: "Redis connection pool factory"
      contains: "redis.asyncio"
    - path: "src/core/logging.py"
      provides: "Structlog configuration"
      contains: "structlog.configure"
    - path: "src/core/sentry.py"
      provides: "Sentry initialization"
      contains: "sentry_sdk.init"
  key_links:
    - from: "src/core/redis.py"
      to: "src/core/config.py"
      via: "import settings.redis_url"
      pattern: "settings.redis_url"
    - from: "src/core/logging.py"
      to: "structlog"
      via: "configure"
      pattern: "structlog.configure"
    - from: "src/core/sentry.py"
      to: "sentry_sdk"
      via: "init"
      pattern: "sentry_sdk.init"
---

<objective>
Configure Redis connection pool, structlog structured logging, and Sentry error tracking.

Purpose: Set up the three infrastructure services that provide caching/queuing (Redis), observability (structlog), and error tracking (Sentry). These are required for INFRA-03, INFRA-04, and INFRA-05.

Output: Three core modules that can be initialized in FastAPI lifespan.
</objective>

<execution_context>
@/Users/tungmbp1423/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tungmbp1423/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Redis connection pool factory</name>
  <files>src/core/redis.py</files>
  <action>
    Create src/core/redis.py with:

    1. `create_redis_pool` factory function:
       ```python
       import redis.asyncio as redis
       from src.core.config import settings

       async def create_redis_pool() -> redis.Redis:
           """Create Redis connection pool for job queue, status, and circuit breaker."""
           return redis.Redis.from_url(
               settings.redis_url,
               decode_responses=True,
               max_connections=20,
           )
       ```

    2. Helper function `check_redis_health`:
       ```python
       async def check_redis_health(pool: redis.Redis) -> bool:
           """Check if Redis is responding."""
           try:
               await pool.ping()
               return True
           except Exception:
               return False
       ```

    3. Document that pool should be stored in app.state and closed on shutdown:
       ```python
       # Usage in lifespan:
       # app.state.redis = await create_redis_pool()
       # yield
       # await app.state.redis.aclose()
       ```
  </action>
  <verify>
    - `python -c "from src.core.redis import create_redis_pool, check_redis_health"` imports
  </verify>
  <done>Redis pool factory ready for FastAPI lifespan integration</done>
</task>

<task type="auto">
  <name>Task 2: Configure structlog with JSON output and required fields</name>
  <files>src/core/logging.py</files>
  <action>
    Create src/core/logging.py with:

    1. `configure_logging` function that sets up structlog:
       ```python
       import logging
       import structlog
       import orjson
       from src.core.config import settings

       def configure_logging() -> None:
           """Configure structlog for structured JSON logging."""

           shared_processors = [
               structlog.contextvars.merge_contextvars,
               structlog.processors.add_log_level,
               structlog.processors.TimeStamper(fmt="iso", utc=True),
               # Add standard fields
               structlog.processors.CallsiteParameterAdder(
                   parameters=[
                       structlog.processors.CallsiteParameter.FUNC_NAME,
                   ]
               ),
           ]

           if settings.environment == "development":
               # Pretty console output for development
               structlog.configure(
                   processors=shared_processors + [
                       structlog.dev.ConsoleRenderer(colors=True),
                   ],
                   wrapper_class=structlog.make_filtering_bound_logger(logging.DEBUG),
                   context_class=dict,
                   logger_factory=structlog.PrintLoggerFactory(),
                   cache_logger_on_first_use=True,
               )
           else:
               # JSON output for production
               structlog.configure(
                   processors=shared_processors + [
                       structlog.processors.format_exc_info,
                       structlog.processors.JSONRenderer(serializer=orjson.dumps),
                   ],
                   wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
                   context_class=dict,
                   logger_factory=structlog.BytesLoggerFactory(),
                   cache_logger_on_first_use=True,
               )
       ```

    2. `get_logger` convenience function:
       ```python
       def get_logger(name: str | None = None) -> structlog.stdlib.BoundLogger:
           """Get a structlog logger, optionally with a name."""
           logger = structlog.get_logger()
           if name:
               logger = logger.bind(logger_name=name)
           return logger
       ```

    3. Document required fields pattern:
       ```python
       # Usage: Bind task context at request start
       # structlog.contextvars.bind_contextvars(
       #     task_id="123",
       #     client_id="456",
       #     agent="personal_tax",
       # )
       #
       # Then any log call includes these:
       # logger.info("processing_started", step="extraction")
       # Output: {"task_id": "123", "client_id": "456", "agent": "personal_tax",
       #          "level": "info", "timestamp": "...", "event": "processing_started", "step": "extraction"}
       ```
  </action>
  <verify>
    - `python -c "from src.core.logging import configure_logging, get_logger; configure_logging(); get_logger().info('test')"`
    - In production mode (ENVIRONMENT=production), output is JSON
  </verify>
  <done>Structlog configured with JSON output, contextvars for task_id/client_id/agent, and required fields</done>
</task>

<task type="auto">
  <name>Task 3: Initialize Sentry error tracking with FastAPI integration</name>
  <files>src/core/sentry.py</files>
  <action>
    Create src/core/sentry.py with:

    1. `init_sentry` function:
       ```python
       import sentry_sdk
       from sentry_sdk.integrations.starlette import StarletteIntegration
       from sentry_sdk.integrations.fastapi import FastApiIntegration
       from src.core.config import settings

       def init_sentry() -> None:
           """Initialize Sentry error tracking if DSN is configured."""
           if not settings.sentry_dsn:
               return  # Skip gracefully if no DSN

           sentry_sdk.init(
               dsn=settings.sentry_dsn,
               environment=settings.environment,
               traces_sample_rate=0.1,  # 10% of transactions for performance monitoring
               send_default_pii=False,  # Never send PII (CPA data sensitivity requirement)
               integrations=[
                   StarletteIntegration(
                       transaction_style="endpoint",
                   ),
                   FastApiIntegration(
                       transaction_style="endpoint",
                       failed_request_status_codes={*range(500, 600)},  # Only 5xx errors
                   ),
               ],
           )
       ```

    2. Helper to test Sentry:
       ```python
       def capture_test_exception() -> None:
           """Capture a test exception to verify Sentry is working."""
           try:
               raise ValueError("Sentry test exception")
           except ValueError:
               sentry_sdk.capture_exception()
       ```

    3. Document that it should be called before FastAPI app creation but after config loads
  </action>
  <verify>
    - `python -c "from src.core.sentry import init_sentry; init_sentry()"` runs without error (no DSN = graceful skip)
    - With SENTRY_DSN set, initialization happens
  </verify>
  <done>Sentry integration configured to capture only 5xx errors, no PII, graceful skip when DSN not set</done>
</task>

</tasks>

<verification>
1. Redis: `python -c "from src.core.redis import create_redis_pool"` imports
2. Logging: `python -c "from src.core.logging import configure_logging; configure_logging()"` runs
3. Sentry: `python -c "from src.core.sentry import init_sentry; init_sentry()"` runs without error
4. All modules import settings from config: `grep -l "from src.core.config import" src/core/*.py`
</verification>

<success_criteria>
- Redis pool factory creates connection pool from settings.redis_url
- Structlog outputs JSON with timestamp, level, and supports task_id/client_id/agent via contextvars
- Sentry initializes only when DSN provided, captures only 5xx errors
- No PII sent to Sentry (send_default_pii=False)
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md`
</output>
