---
phase: 01-foundation
plan: 04
type: execute
wave: 3
depends_on: ["01-01", "01-02"]
files_modified:
  - alembic.ini
  - migrations/env.py
  - migrations/script.py.mako
  - migrations/versions/001_initial_schema.py
autonomous: true

must_haves:
  truths:
    - "alembic upgrade head runs without error"
    - "All 11 tables created in PostgreSQL"
    - "pgvector extension enabled and Vector columns work"
  artifacts:
    - path: "alembic.ini"
      provides: "Alembic configuration"
      contains: "sqlalchemy.url"
    - path: "migrations/env.py"
      provides: "Async migration environment"
      contains: "run_async_migrations"
    - path: "migrations/versions/001_initial_schema.py"
      provides: "Initial database schema"
      contains: "def upgrade"
  key_links:
    - from: "migrations/env.py"
      to: "src/models"
      via: "import all models"
      pattern: "from src.models import"
    - from: "migrations/env.py"
      to: "pgvector"
      via: "type registration"
      pattern: "ischema_names.*vector.*Vector"
---

<objective>
Set up Alembic with async support, pgvector type registration, and create the initial migration for the complete schema.

Purpose: Enable database migrations with proper async PostgreSQL support and pgvector extension. This satisfies INFRA-06 (migrations run without error) and provides the schema for INFRA-02.

Output: Alembic configuration and initial migration that creates all 11 tables with proper types including Vector columns.
</objective>

<execution_context>
@/Users/tungmbp1423/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tungmbp1423/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Initialize Alembic with async configuration and pgvector support</name>
  <files>alembic.ini, migrations/env.py, migrations/script.py.mako, migrations/README</files>
  <action>
    1. Initialize Alembic:
       ```bash
       uv run alembic init migrations
       ```

    2. Update alembic.ini:
       - Set `sqlalchemy.url` to use environment variable:
         ```ini
         sqlalchemy.url = ${DATABASE_URL}
         ```
       - Or configure to read from env.py (preferred for async)

    3. Replace migrations/env.py with async version:
       ```python
       import asyncio
       from logging.config import fileConfig

       from sqlalchemy import pool
       from sqlalchemy.ext.asyncio import async_engine_from_config
       from alembic import context
       from pgvector.sqlalchemy import Vector

       from src.core.config import settings
       from src.models import Base
       # Import all models to register them with Base.metadata
       from src.models import (
           Task, Escalation, TaskArtifact,
           Client, ClientProfileEntry,
           FeedbackEntry, DocumentEmbedding,
           SkillFile, SkillEmbedding,
           AgentLog, AgentMetric,
       )

       config = context.config

       if config.config_file_name is not None:
           fileConfig(config.config_file_name)

       target_metadata = Base.metadata

       def do_run_migrations(connection):
           # Register pgvector type so Alembic recognizes it
           connection.dialect.ischema_names['vector'] = Vector

           context.configure(
               connection=connection,
               target_metadata=target_metadata,
               compare_type=True,
           )

           with context.begin_transaction():
               context.run_migrations()

       async def run_async_migrations():
           configuration = config.get_section(config.config_ini_section) or {}
           configuration["sqlalchemy.url"] = settings.database_url

           connectable = async_engine_from_config(
               configuration,
               prefix="sqlalchemy.",
               poolclass=pool.NullPool,
           )

           async with connectable.connect() as connection:
               await connection.run_sync(do_run_migrations)

           await connectable.dispose()

       def run_migrations_offline():
           url = settings.database_url
           context.configure(
               url=url,
               target_metadata=target_metadata,
               literal_binds=True,
               dialect_opts={"paramstyle": "named"},
           )

           with context.begin_transaction():
               context.run_migrations()

       def run_migrations_online():
           asyncio.run(run_async_migrations())

       if context.is_offline_mode():
           run_migrations_offline()
       else:
           run_migrations_online()
       ```

    4. Keep script.py.mako as default (Alembic template for new migrations)
  </action>
  <verify>
    - `uv run alembic --help` works
    - migrations/env.py contains `run_async_migrations` function
    - migrations/env.py imports all models from src.models
    - pgvector type registration present: `grep "ischema_names" migrations/env.py`
  </verify>
  <done>Alembic configured for async PostgreSQL with pgvector type support</done>
</task>

<task type="auto">
  <name>Task 2: Generate initial migration with all models</name>
  <files>migrations/versions/001_initial_schema.py</files>
  <action>
    1. Ensure PostgreSQL is running with pgvector extension:
       - If using Docker: `docker run -d --name rookie-db -e POSTGRES_PASSWORD=postgres -p 5432:5432 pgvector/pgvector:pg16`
       - Or ensure existing PostgreSQL has pgvector: `CREATE EXTENSION IF NOT EXISTS vector;`

    2. Create .env from .env.example if not exists, with valid DATABASE_URL

    3. Generate migration (autogenerate from models):
       ```bash
       uv run alembic revision --autogenerate -m "Initial schema with all models"
       ```

    4. Review generated migration and ensure:
       - All 11 tables present (tasks, clients, client_profile_entries, task_artifacts, escalations, feedback_entries, skill_files, agent_logs, agent_metrics, document_embeddings, skill_embeddings)
       - Vector columns have correct dimension (1536)
       - Foreign keys properly defined
       - Indexes created as needed

    5. Add pgvector extension creation at top of upgrade():
       ```python
       def upgrade():
           # Enable pgvector extension
           op.execute('CREATE EXTENSION IF NOT EXISTS vector')

           # ... rest of migration
       ```

    6. Run migration to verify:
       ```bash
       uv run alembic upgrade head
       ```

    7. Verify tables exist:
       ```bash
       # Connect to database and check
       psql $DATABASE_URL -c "\dt"
       ```
  </action>
  <verify>
    - `uv run alembic upgrade head` completes without error
    - `uv run alembic current` shows head revision
    - All 11 tables exist in database
  </verify>
  <done>Initial migration creates complete schema with all tables and pgvector support</done>
</task>

</tasks>

<verification>
1. `uv run alembic upgrade head` runs without error
2. `uv run alembic current` shows the initial migration as current
3. Database contains all expected tables:
   - tasks
   - clients
   - client_profile_entries
   - task_artifacts
   - escalations
   - feedback_entries
   - skill_files
   - agent_logs
   - agent_metrics
   - document_embeddings
   - skill_embeddings
4. Vector columns work: `SELECT '[1,2,3]'::vector;` doesn't error
</verification>

<success_criteria>
- Alembic initialized with async PostgreSQL support
- pgvector type registered in env.py (no "Did not recognize type 'vector'" warnings)
- Initial migration creates all 11 tables
- `alembic upgrade head` completes successfully
- `alembic downgrade base` works (clean rollback)
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-04-SUMMARY.md`
</output>
