---
phase: 02-core-framework
plan: 06
type: execute
wave: 4
depends_on:
  - 02-04
  - 02-05
files_modified:
  - src/search/__init__.py
  - src/search/embeddings.py
  - src/search/hybrid.py
  - tests/search/__init__.py
  - tests/search/test_embeddings.py
  - tests/search/test_hybrid.py
  # Note: Migration file created by Alembic with auto-generated name
autonomous: true

must_haves:
  truths:
    - "Embedding client generates vectors using Voyage AI"
    - "Hybrid search combines pgvector (semantic) + BM25 (keyword)"
    - "RRF fusion normalizes and combines search scores"
    - "Search returns results ranked by hybrid score"
    - "All search tests pass"
  artifacts:
    - path: "src/search/embeddings.py"
      provides: "Voyage AI embedding client"
      contains: "class EmbeddingClient"
    - path: "src/search/hybrid.py"
      provides: "Hybrid search with RRF fusion"
      contains: "async def hybrid_search"
  key_links:
    - from: "src/search/embeddings.py"
      to: "voyageai"
      via: "import"
      pattern: "import voyageai"
    - from: "src/search/hybrid.py"
      to: "src/search/embeddings.py"
      via: "import"
      pattern: "from src.search.embeddings import"
---

<objective>
Implement hybrid search combining pgvector semantic search with BM25 full-text search using Reciprocal Rank Fusion (RRF).

Purpose: Enable agents to search skills and documents using both semantic similarity (vector search) and keyword matching (BM25), providing better recall and precision than either method alone.

Output: Working hybrid search that combines pgvector cosine similarity with PostgreSQL full-text search using RRF score fusion.
</objective>

<execution_context>
@/Users/tungmbp1423/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tungmbp1423/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-framework/02-RESEARCH.md
@src/models/skill.py
@src/models/artifact.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Voyage AI embedding client</name>
  <files>src/search/__init__.py, src/search/embeddings.py</files>
  <action>
    1. Create src/search/__init__.py (empty module init)

    2. Create src/search/embeddings.py:

    ```python
    """Embedding client for generating vector embeddings.

    Uses Voyage AI for embeddings (Anthropic-recommended partner).
    Voyage voyage-3-lite model provides 1024-dimensional embeddings.

    Note: The SkillEmbedding model uses 1536 dimensions (OpenAI default).
    If using Voyage (1024 dims), update the model or use voyage-3 (1024)
    and update the Vector dimension. For this implementation, we support
    both by making dimension configurable.
    """

    import asyncio
    from typing import Sequence

    import structlog

    logger = structlog.get_logger()


    class EmbeddingClient:
        """Client for generating text embeddings.

        Supports Voyage AI for production use and a mock mode for testing.
        """

        def __init__(
            self,
            api_key: str | None = None,
            model: str = "voyage-3-lite",
            dimension: int = 1024,
            use_mock: bool = False,
        ):
            """Initialize embedding client.

            Args:
                api_key: Voyage AI API key (required unless use_mock=True)
                model: Embedding model name
                dimension: Expected embedding dimension
                use_mock: If True, generate random embeddings for testing
            """
            self.model = model
            self.dimension = dimension
            self.use_mock = use_mock

            if use_mock:
                self._client = None
                logger.warning(
                    "embedding_client_mock_mode",
                    message="Using mock embeddings - not for production",
                )
            else:
                if api_key is None:
                    raise ValueError("api_key required when not in mock mode")
                try:
                    import voyageai

                    self._client = voyageai.Client(api_key=api_key)
                except ImportError:
                    raise ImportError(
                        "voyageai package required. Install with: uv add voyageai"
                    )

        async def embed_texts(
            self,
            texts: Sequence[str],
            input_type: str = "document",
        ) -> list[list[float]]:
            """Embed multiple texts.

            Args:
                texts: Texts to embed
                input_type: "document" for indexing, "query" for search

            Returns:
                List of embedding vectors
            """
            if not texts:
                return []

            if self.use_mock:
                return self._generate_mock_embeddings(len(texts))

            # Voyage client is sync, run in executor
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None,
                lambda: self._client.embed(
                    texts=list(texts),
                    model=self.model,
                    input_type=input_type,
                ),
            )

            logger.debug(
                "embeddings_generated",
                count=len(texts),
                model=self.model,
                input_type=input_type,
            )

            return result.embeddings

        async def embed_query(self, text: str) -> list[float]:
            """Embed a single query text.

            Uses input_type="query" for better search relevance.

            Args:
                text: Query text to embed

            Returns:
                Embedding vector
            """
            embeddings = await self.embed_texts([text], input_type="query")
            return embeddings[0]

        async def embed_document(self, text: str) -> list[float]:
            """Embed a single document text.

            Uses input_type="document" for indexing.

            Args:
                text: Document text to embed

            Returns:
                Embedding vector
            """
            embeddings = await self.embed_texts([text], input_type="document")
            return embeddings[0]

        async def embed_documents(
            self,
            texts: Sequence[str],
            batch_size: int = 128,
        ) -> list[list[float]]:
            """Embed multiple documents with batching.

            Voyage has a limit of 128 texts per request.

            Args:
                texts: Document texts to embed
                batch_size: Texts per batch (max 128 for Voyage)

            Returns:
                List of embedding vectors
            """
            if not texts:
                return []

            all_embeddings: list[list[float]] = []

            for i in range(0, len(texts), batch_size):
                batch = texts[i : i + batch_size]
                embeddings = await self.embed_texts(batch, input_type="document")
                all_embeddings.extend(embeddings)

            return all_embeddings

        def _generate_mock_embeddings(self, count: int) -> list[list[float]]:
            """Generate random mock embeddings for testing."""
            import random

            return [
                [random.random() for _ in range(self.dimension)] for _ in range(count)
            ]


    # Module-level singleton for convenience
    _embedding_client: EmbeddingClient | None = None


    def get_embedding_client(
        api_key: str | None = None,
        use_mock: bool = False,
    ) -> EmbeddingClient:
        """Get or create the default embedding client.

        Args:
            api_key: Voyage AI API key
            use_mock: Use mock embeddings for testing

        Returns:
            EmbeddingClient instance
        """
        global _embedding_client

        if _embedding_client is None:
            _embedding_client = EmbeddingClient(
                api_key=api_key,
                use_mock=use_mock,
            )

        return _embedding_client


    def reset_embedding_client() -> None:
        """Reset the embedding client. Primarily for testing."""
        global _embedding_client
        _embedding_client = None


    __all__ = [
        "EmbeddingClient",
        "get_embedding_client",
        "reset_embedding_client",
    ]
    ```
  </action>
  <verify>
    - `python -c "from src.search.embeddings import EmbeddingClient"` succeeds
    - Client supports mock mode for testing without API key
  </verify>
  <done>Embedding client exists with Voyage AI support and mock mode</done>
</task>

<task type="auto">
  <name>Task 2: Create hybrid search with RRF fusion</name>
  <files>src/search/hybrid.py</files>
  <action>
    Create src/search/hybrid.py:

    ```python
    """Hybrid search combining semantic and keyword search with RRF fusion.

    Implements hybrid search that combines:
    - pgvector: Semantic similarity using cosine distance
    - PostgreSQL full-text search: Keyword matching with ts_rank

    Scores are combined using Reciprocal Rank Fusion (RRF) which
    normalizes rankings from different scoring methods.

    RRF formula: score = sum(1 / (k + rank)) where k=60 is standard.
    """

    from dataclasses import dataclass
    from typing import Any

    import structlog
    from sqlalchemy import func, select, text
    from sqlalchemy.ext.asyncio import AsyncSession

    from src.models.skill import SkillEmbedding, SkillFile
    from src.search.embeddings import EmbeddingClient

    logger = structlog.get_logger()

    # RRF constant (standard value from literature)
    RRF_K = 60


    @dataclass
    class SearchResult:
        """A single search result with hybrid score."""

        id: int
        skill_file_id: int
        skill_name: str
        chunk_text: str
        semantic_rank: int | None
        keyword_rank: int | None
        hybrid_score: float

        @property
        def source_info(self) -> str:
            """Human-readable source information."""
            sources = []
            if self.semantic_rank is not None:
                sources.append(f"semantic:{self.semantic_rank}")
            if self.keyword_rank is not None:
                sources.append(f"keyword:{self.keyword_rank}")
            return ", ".join(sources) if sources else "unknown"


    async def semantic_search(
        session: AsyncSession,
        query_embedding: list[float],
        limit: int = 20,
    ) -> list[tuple[int, int]]:
        """Perform semantic search using pgvector cosine distance.

        Args:
            session: SQLAlchemy async session
            query_embedding: Query embedding vector
            limit: Maximum results to return

        Returns:
            List of (embedding_id, rank) tuples
        """
        # Convert embedding to PostgreSQL array format
        embedding_str = "[" + ",".join(str(x) for x in query_embedding) + "]"

        # Use cosine distance (<=>)
        query = (
            select(
                SkillEmbedding.id,
                func.row_number()
                .over(
                    order_by=SkillEmbedding.embedding.cosine_distance(
                        text(f"'{embedding_str}'::vector")
                    )
                )
                .label("rank"),
            )
            .order_by(
                SkillEmbedding.embedding.cosine_distance(
                    text(f"'{embedding_str}'::vector")
                )
            )
            .limit(limit)
        )

        result = await session.execute(query)
        rows = result.fetchall()

        return [(row.id, row.rank) for row in rows]


    async def keyword_search(
        session: AsyncSession,
        query_text: str,
        limit: int = 20,
    ) -> list[tuple[int, int]]:
        """Perform keyword search using PostgreSQL full-text search.

        Uses ts_rank for relevance scoring. Note: This uses basic ts_rank,
        not BM25 (which would require pg_textsearch extension).

        Args:
            session: SQLAlchemy async session
            query_text: Search query text
            limit: Maximum results to return

        Returns:
            List of (embedding_id, rank) tuples
        """
        # Create tsquery from search text
        # plainto_tsquery handles plain text input
        query = (
            select(
                SkillEmbedding.id,
                func.row_number()
                .over(
                    order_by=func.ts_rank(
                        func.to_tsvector("english", SkillEmbedding.chunk_text),
                        func.plainto_tsquery("english", query_text),
                    ).desc()
                )
                .label("rank"),
            )
            .where(
                func.to_tsvector("english", SkillEmbedding.chunk_text).op("@@")(
                    func.plainto_tsquery("english", query_text)
                )
            )
            .order_by(
                func.ts_rank(
                    func.to_tsvector("english", SkillEmbedding.chunk_text),
                    func.plainto_tsquery("english", query_text),
                ).desc()
            )
            .limit(limit)
        )

        result = await session.execute(query)
        rows = result.fetchall()

        return [(row.id, row.rank) for row in rows]


    def compute_rrf_scores(
        semantic_results: list[tuple[int, int]],
        keyword_results: list[tuple[int, int]],
        k: int = RRF_K,
    ) -> dict[int, dict[str, Any]]:
        """Compute RRF scores from semantic and keyword search results.

        RRF formula: score = sum(1 / (k + rank))

        Args:
            semantic_results: List of (id, rank) from semantic search
            keyword_results: List of (id, rank) from keyword search
            k: RRF constant (default 60)

        Returns:
            Dictionary mapping id to score info:
            {
                id: {
                    "rrf_score": float,
                    "semantic_rank": int | None,
                    "keyword_rank": int | None,
                }
            }
        """
        scores: dict[int, dict[str, Any]] = {}

        # Process semantic results
        for doc_id, rank in semantic_results:
            if doc_id not in scores:
                scores[doc_id] = {
                    "rrf_score": 0.0,
                    "semantic_rank": None,
                    "keyword_rank": None,
                }
            scores[doc_id]["rrf_score"] += 1.0 / (k + rank)
            scores[doc_id]["semantic_rank"] = rank

        # Process keyword results
        for doc_id, rank in keyword_results:
            if doc_id not in scores:
                scores[doc_id] = {
                    "rrf_score": 0.0,
                    "semantic_rank": None,
                    "keyword_rank": None,
                }
            scores[doc_id]["rrf_score"] += 1.0 / (k + rank)
            scores[doc_id]["keyword_rank"] = rank

        return scores


    async def hybrid_search(
        session: AsyncSession,
        query_text: str,
        embedding_client: EmbeddingClient,
        limit: int = 10,
        semantic_weight: float = 0.5,
    ) -> list[SearchResult]:
        """Perform hybrid search combining semantic and keyword search.

        Args:
            session: SQLAlchemy async session
            query_text: Search query
            embedding_client: Client for generating query embedding
            limit: Maximum results to return
            semantic_weight: Not used in RRF (weights are implicit in ranking)

        Returns:
            List of SearchResult objects sorted by hybrid score
        """
        # Generate query embedding
        query_embedding = await embedding_client.embed_query(query_text)

        # Perform both searches in parallel
        semantic_task = semantic_search(session, query_embedding, limit=limit * 2)
        keyword_task = keyword_search(session, query_text, limit=limit * 2)

        # Note: These are coroutines, not asyncio tasks
        # Execute sequentially (could use asyncio.gather for true parallelism)
        semantic_results = await semantic_task
        keyword_results = await keyword_task

        logger.debug(
            "hybrid_search_components",
            query=query_text[:50],
            semantic_count=len(semantic_results),
            keyword_count=len(keyword_results),
        )

        # Compute RRF scores
        rrf_scores = compute_rrf_scores(semantic_results, keyword_results)

        if not rrf_scores:
            return []

        # Get document details for results
        doc_ids = list(rrf_scores.keys())

        query = (
            select(SkillEmbedding, SkillFile.name)
            .join(SkillFile, SkillEmbedding.skill_file_id == SkillFile.id)
            .where(SkillEmbedding.id.in_(doc_ids))
        )

        result = await session.execute(query)
        rows = result.fetchall()

        # Build SearchResult objects
        results: list[SearchResult] = []
        for embedding, skill_name in rows:
            score_info = rrf_scores[embedding.id]
            results.append(
                SearchResult(
                    id=embedding.id,
                    skill_file_id=embedding.skill_file_id,
                    skill_name=skill_name,
                    chunk_text=embedding.chunk_text,
                    semantic_rank=score_info["semantic_rank"],
                    keyword_rank=score_info["keyword_rank"],
                    hybrid_score=score_info["rrf_score"],
                )
            )

        # Sort by hybrid score descending
        results.sort(key=lambda x: x.hybrid_score, reverse=True)

        # Limit results
        results = results[:limit]

        logger.info(
            "hybrid_search_completed",
            query=query_text[:50],
            result_count=len(results),
            top_score=results[0].hybrid_score if results else 0,
        )

        return results


    async def search_skills(
        session: AsyncSession,
        query: str,
        embedding_client: EmbeddingClient,
        limit: int = 10,
    ) -> list[SearchResult]:
        """Search skill embeddings using hybrid search.

        Convenience wrapper around hybrid_search for skill-specific searches.

        Args:
            session: SQLAlchemy async session
            query: Search query
            embedding_client: Embedding client
            limit: Maximum results

        Returns:
            List of SearchResult objects
        """
        return await hybrid_search(
            session=session,
            query_text=query,
            embedding_client=embedding_client,
            limit=limit,
        )


    __all__ = [
        "SearchResult",
        "hybrid_search",
        "search_skills",
        "semantic_search",
        "keyword_search",
        "compute_rrf_scores",
        "RRF_K",
    ]
    ```
  </action>
  <verify>
    - `python -c "from src.search.hybrid import hybrid_search, SearchResult"` succeeds
    - Module implements RRF fusion for combining search results
  </verify>
  <done>Hybrid search exists with RRF fusion combining semantic and keyword search</done>
</task>

<task type="auto">
  <name>Task 3: Update search __init__.py with exports</name>
  <files>src/search/__init__.py</files>
  <action>
    Update src/search/__init__.py:

    ```python
    """Search module for hybrid semantic and keyword search.

    Provides:
    - EmbeddingClient: Generate embeddings using Voyage AI
    - hybrid_search: Combined semantic + keyword search with RRF
    """

    from src.search.embeddings import (
        EmbeddingClient,
        get_embedding_client,
        reset_embedding_client,
    )
    from src.search.hybrid import (
        RRF_K,
        SearchResult,
        compute_rrf_scores,
        hybrid_search,
        keyword_search,
        search_skills,
        semantic_search,
    )

    __all__ = [
        # Embeddings
        "EmbeddingClient",
        "get_embedding_client",
        "reset_embedding_client",
        # Hybrid search
        "SearchResult",
        "hybrid_search",
        "search_skills",
        "semantic_search",
        "keyword_search",
        "compute_rrf_scores",
        "RRF_K",
    ]
    ```
  </action>
  <verify>
    - `python -c "from src.search import EmbeddingClient, hybrid_search, SearchResult"` succeeds
  </verify>
  <done>Search module exports all embedding and search functions</done>
</task>

<task type="auto">
  <name>Task 4: Create Alembic migration for full-text search index</name>
  <files>migrations/versions/ (Alembic auto-generates filename)</files>
  <action>
    Create a new Alembic migration for full-text search index.

    Run: `alembic revision -m "add_fulltext_index_to_skill_embeddings"`

    Then edit the generated file:

    ```python
    """add_fulltext_index_to_skill_embeddings

    Revision ID: [auto-generated]
    Revises: [previous]
    Create Date: [auto-generated]
    """

    from typing import Sequence, Union

    import sqlalchemy as sa
    from alembic import op

    # revision identifiers, used by Alembic.
    revision: str = "[auto-generated]"
    down_revision: Union[str, None] = "[previous]"
    branch_labels: Union[str, Sequence[str], None] = None
    depends_on: Union[str, Sequence[str], None] = None


    def upgrade() -> None:
        """Add GIN index for full-text search on skill_embeddings.chunk_text."""
        # Create GIN index for full-text search
        op.execute(
            """
            CREATE INDEX IF NOT EXISTS skill_embeddings_chunk_text_gin_idx
            ON skill_embeddings
            USING GIN (to_tsvector('english', chunk_text))
            """
        )

        # Add index on skill_file_id for joins
        op.create_index(
            "ix_skill_embeddings_skill_file_id",
            "skill_embeddings",
            ["skill_file_id"],
            if_not_exists=True,
        )


    def downgrade() -> None:
        """Remove full-text search index."""
        op.execute(
            "DROP INDEX IF EXISTS skill_embeddings_chunk_text_gin_idx"
        )
        op.drop_index(
            "ix_skill_embeddings_skill_file_id",
            table_name="skill_embeddings",
            if_exists=True,
        )
    ```

    Note: The actual revision ID and down_revision will be auto-generated by Alembic.
    Run `alembic revision -m "add_fulltext_index_to_skill_embeddings"` to create the file,
    then modify its contents.
  </action>
  <verify>
    - `alembic upgrade head` runs without error
    - Verify GIN index exists: `psql -c "SELECT indexname FROM pg_indexes WHERE tablename='skill_embeddings' AND indexname LIKE '%gin%';"` returns `skill_embeddings_chunk_text_gin_idx`
  </verify>
  <done>Full-text search GIN index migration created and applied</done>
</task>

<task type="auto">
  <name>Task 5: Create search tests</name>
  <files>tests/search/__init__.py, tests/search/test_embeddings.py, tests/search/test_hybrid.py</files>
  <action>
    1. Create tests/search/__init__.py (empty)

    2. Create tests/search/test_embeddings.py:

    ```python
    """Tests for embedding client."""

    import pytest

    from src.search.embeddings import (
        EmbeddingClient,
        get_embedding_client,
        reset_embedding_client,
    )


    class TestEmbeddingClient:
        """Tests for EmbeddingClient."""

        def setup_method(self) -> None:
            """Reset client before each test."""
            reset_embedding_client()

        @pytest.mark.asyncio
        async def test_mock_mode_generates_embeddings(self) -> None:
            """Mock mode generates embeddings without API key."""
            client = EmbeddingClient(use_mock=True)

            embeddings = await client.embed_texts(["Hello world"])

            assert len(embeddings) == 1
            assert len(embeddings[0]) == 1024  # Default dimension

        @pytest.mark.asyncio
        async def test_mock_mode_batch_embeddings(self) -> None:
            """Mock mode handles multiple texts."""
            client = EmbeddingClient(use_mock=True)

            embeddings = await client.embed_texts(["One", "Two", "Three"])

            assert len(embeddings) == 3

        @pytest.mark.asyncio
        async def test_embed_query_returns_single_vector(self) -> None:
            """embed_query returns single embedding."""
            client = EmbeddingClient(use_mock=True)

            embedding = await client.embed_query("Search query")

            assert len(embedding) == 1024

        @pytest.mark.asyncio
        async def test_embed_document_returns_single_vector(self) -> None:
            """embed_document returns single embedding."""
            client = EmbeddingClient(use_mock=True)

            embedding = await client.embed_document("Document content")

            assert len(embedding) == 1024

        @pytest.mark.asyncio
        async def test_embed_documents_batches_correctly(self) -> None:
            """embed_documents handles batching."""
            client = EmbeddingClient(use_mock=True)

            # More than default batch size
            texts = [f"Document {i}" for i in range(150)]
            embeddings = await client.embed_documents(texts, batch_size=50)

            assert len(embeddings) == 150

        @pytest.mark.asyncio
        async def test_empty_texts_returns_empty(self) -> None:
            """Empty input returns empty output."""
            client = EmbeddingClient(use_mock=True)

            embeddings = await client.embed_texts([])

            assert embeddings == []

        def test_requires_api_key_without_mock(self) -> None:
            """Raises error when no API key and not mock mode."""
            with pytest.raises(ValueError) as exc_info:
                EmbeddingClient(use_mock=False)

            assert "api_key required" in str(exc_info.value)

        def test_custom_dimension(self) -> None:
            """Respects custom dimension setting."""
            client = EmbeddingClient(use_mock=True, dimension=768)

            assert client.dimension == 768


    class TestGetEmbeddingClient:
        """Tests for get_embedding_client singleton."""

        def setup_method(self) -> None:
            """Reset client before each test."""
            reset_embedding_client()

        def test_returns_singleton(self) -> None:
            """Returns same instance on repeated calls."""
            c1 = get_embedding_client(use_mock=True)
            c2 = get_embedding_client(use_mock=True)

            assert c1 is c2

        def test_reset_creates_new_instance(self) -> None:
            """reset_embedding_client allows new instance."""
            c1 = get_embedding_client(use_mock=True)
            reset_embedding_client()
            c2 = get_embedding_client(use_mock=True)

            assert c1 is not c2
    ```

    3. Create tests/search/test_hybrid.py:

    ```python
    """Tests for hybrid search."""

    from unittest.mock import AsyncMock, MagicMock, patch

    import pytest
    from sqlalchemy.ext.asyncio import AsyncSession

    from src.search.embeddings import EmbeddingClient
    from src.search.hybrid import (
        RRF_K,
        SearchResult,
        compute_rrf_scores,
    )


    class TestComputeRrfScores:
        """Tests for RRF score computation."""

        def test_combines_semantic_and_keyword_scores(self) -> None:
            """RRF combines scores from both sources."""
            semantic_results = [(1, 1), (2, 2), (3, 3)]  # (id, rank)
            keyword_results = [(1, 2), (4, 1)]  # Doc 1 appears in both

            scores = compute_rrf_scores(semantic_results, keyword_results)

            # Doc 1 should have highest score (appears in both)
            assert scores[1]["rrf_score"] > scores[2]["rrf_score"]
            assert scores[1]["semantic_rank"] == 1
            assert scores[1]["keyword_rank"] == 2

        def test_handles_semantic_only_results(self) -> None:
            """Documents only in semantic results get scores."""
            semantic_results = [(1, 1), (2, 2)]
            keyword_results = []

            scores = compute_rrf_scores(semantic_results, keyword_results)

            assert 1 in scores
            assert scores[1]["keyword_rank"] is None
            assert scores[1]["semantic_rank"] == 1

        def test_handles_keyword_only_results(self) -> None:
            """Documents only in keyword results get scores."""
            semantic_results = []
            keyword_results = [(1, 1), (2, 2)]

            scores = compute_rrf_scores(semantic_results, keyword_results)

            assert 1 in scores
            assert scores[1]["semantic_rank"] is None
            assert scores[1]["keyword_rank"] == 1

        def test_rrf_formula_correct(self) -> None:
            """RRF score follows 1/(k+rank) formula."""
            semantic_results = [(1, 1)]
            keyword_results = []

            scores = compute_rrf_scores(semantic_results, keyword_results, k=60)

            # Score should be 1/(60+1) = 1/61
            expected = 1.0 / (60 + 1)
            assert abs(scores[1]["rrf_score"] - expected) < 0.0001

        def test_combined_rrf_formula(self) -> None:
            """RRF correctly sums scores when doc appears in both."""
            semantic_results = [(1, 1)]
            keyword_results = [(1, 1)]

            scores = compute_rrf_scores(semantic_results, keyword_results, k=60)

            # Score should be 2 * 1/(60+1)
            expected = 2.0 / (60 + 1)
            assert abs(scores[1]["rrf_score"] - expected) < 0.0001

        def test_empty_inputs_returns_empty(self) -> None:
            """Empty inputs return empty scores."""
            scores = compute_rrf_scores([], [])

            assert scores == {}


    class TestSearchResult:
        """Tests for SearchResult dataclass."""

        def test_source_info_both_sources(self) -> None:
            """source_info shows both sources."""
            result = SearchResult(
                id=1,
                skill_file_id=1,
                skill_name="test",
                chunk_text="content",
                semantic_rank=1,
                keyword_rank=2,
                hybrid_score=0.5,
            )

            info = result.source_info
            assert "semantic:1" in info
            assert "keyword:2" in info

        def test_source_info_semantic_only(self) -> None:
            """source_info shows only semantic when keyword is None."""
            result = SearchResult(
                id=1,
                skill_file_id=1,
                skill_name="test",
                chunk_text="content",
                semantic_rank=1,
                keyword_rank=None,
                hybrid_score=0.5,
            )

            info = result.source_info
            assert "semantic:1" in info
            assert "keyword" not in info

        def test_source_info_keyword_only(self) -> None:
            """source_info shows only keyword when semantic is None."""
            result = SearchResult(
                id=1,
                skill_file_id=1,
                skill_name="test",
                chunk_text="content",
                semantic_rank=None,
                keyword_rank=1,
                hybrid_score=0.5,
            )

            info = result.source_info
            assert "keyword:1" in info
            assert "semantic" not in info


    class TestHybridSearch:
        """Tests for hybrid_search function."""

        @pytest.mark.asyncio
        async def test_returns_sorted_results(self) -> None:
            """Results are sorted by hybrid score descending."""
            # This is a unit test of the sorting logic
            # Full integration test would require database

            results = [
                SearchResult(
                    id=1, skill_file_id=1, skill_name="a",
                    chunk_text="", semantic_rank=1, keyword_rank=None,
                    hybrid_score=0.1,
                ),
                SearchResult(
                    id=2, skill_file_id=1, skill_name="b",
                    chunk_text="", semantic_rank=1, keyword_rank=1,
                    hybrid_score=0.5,  # Highest
                ),
                SearchResult(
                    id=3, skill_file_id=1, skill_name="c",
                    chunk_text="", semantic_rank=2, keyword_rank=None,
                    hybrid_score=0.2,
                ),
            ]

            # Sort as hybrid_search does
            results.sort(key=lambda x: x.hybrid_score, reverse=True)

            assert results[0].id == 2  # Highest score first
            assert results[1].id == 3
            assert results[2].id == 1
    ```
  </action>
  <verify>
    - `pytest tests/search/ -v` passes all tests
    - RRF score computation is correct
    - Embedding client mock mode works
  </verify>
  <done>Search tests pass, covering embeddings and RRF fusion logic</done>
</task>

</tasks>

<verification>
1. `python -c "from src.search import EmbeddingClient, hybrid_search, SearchResult"` imports successfully
2. `pytest tests/search/ -v` passes all tests
3. Embedding client works in mock mode for testing
4. RRF fusion correctly combines semantic and keyword ranks
5. Migration adds full-text search index
</verification>

<success_criteria>
- EmbeddingClient generates embeddings (mock mode for testing)
- hybrid_search combines pgvector and full-text search
- RRF fusion normalizes and combines search scores
- Results sorted by hybrid score descending
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-framework/02-06-SUMMARY.md`
</output>
